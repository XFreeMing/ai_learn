{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.5620617270469666\n",
      "w: tensor([[-0.1891],\n",
      "        [-1.9677]], requires_grad=True)   b: tensor([[0.0161]], requires_grad=True)\n",
      "Epoch 2/100, Loss: 0.5477286577224731\n",
      "w: tensor([[-0.0421],\n",
      "        [-2.0446]], requires_grad=True)   b: tensor([[0.0291]], requires_grad=True)\n",
      "Epoch 3/100, Loss: 0.5355436205863953\n",
      "w: tensor([[ 0.0840],\n",
      "        [-2.1164]], requires_grad=True)   b: tensor([[0.0397]], requires_grad=True)\n",
      "Epoch 4/100, Loss: 0.5250095725059509\n",
      "w: tensor([[ 0.1932],\n",
      "        [-2.1845]], requires_grad=True)   b: tensor([[0.0484]], requires_grad=True)\n",
      "Epoch 5/100, Loss: 0.5157642960548401\n",
      "w: tensor([[ 0.2884],\n",
      "        [-2.2497]], requires_grad=True)   b: tensor([[0.0556]], requires_grad=True)\n",
      "Epoch 6/100, Loss: 0.507541298866272\n",
      "w: tensor([[ 0.3722],\n",
      "        [-2.3124]], requires_grad=True)   b: tensor([[0.0616]], requires_grad=True)\n",
      "Epoch 7/100, Loss: 0.5001413822174072\n",
      "w: tensor([[ 0.4463],\n",
      "        [-2.3732]], requires_grad=True)   b: tensor([[0.0668]], requires_grad=True)\n",
      "Epoch 8/100, Loss: 0.49341335892677307\n",
      "w: tensor([[ 0.5124],\n",
      "        [-2.4321]], requires_grad=True)   b: tensor([[0.0712]], requires_grad=True)\n",
      "Epoch 9/100, Loss: 0.48724156618118286\n",
      "w: tensor([[ 0.5717],\n",
      "        [-2.4895]], requires_grad=True)   b: tensor([[0.0751]], requires_grad=True)\n",
      "Epoch 10/100, Loss: 0.48153579235076904\n",
      "w: tensor([[ 0.6253],\n",
      "        [-2.5455]], requires_grad=True)   b: tensor([[0.0784]], requires_grad=True)\n",
      "Epoch 11/100, Loss: 0.476225346326828\n",
      "w: tensor([[ 0.6739],\n",
      "        [-2.6001]], requires_grad=True)   b: tensor([[0.0814]], requires_grad=True)\n",
      "Epoch 12/100, Loss: 0.4712536334991455\n",
      "w: tensor([[ 0.7182],\n",
      "        [-2.6534]], requires_grad=True)   b: tensor([[0.0841]], requires_grad=True)\n",
      "Epoch 13/100, Loss: 0.4665753245353699\n",
      "w: tensor([[ 0.7588],\n",
      "        [-2.7056]], requires_grad=True)   b: tensor([[0.0865]], requires_grad=True)\n",
      "Epoch 14/100, Loss: 0.4621536433696747\n",
      "w: tensor([[ 0.7962],\n",
      "        [-2.7566]], requires_grad=True)   b: tensor([[0.0887]], requires_grad=True)\n",
      "Epoch 15/100, Loss: 0.4579582214355469\n",
      "w: tensor([[ 0.8309],\n",
      "        [-2.8065]], requires_grad=True)   b: tensor([[0.0907]], requires_grad=True)\n",
      "Epoch 16/100, Loss: 0.453963965177536\n",
      "w: tensor([[ 0.8630],\n",
      "        [-2.8555]], requires_grad=True)   b: tensor([[0.0925]], requires_grad=True)\n",
      "Epoch 17/100, Loss: 0.4501491189002991\n",
      "w: tensor([[ 0.8930],\n",
      "        [-2.9034]], requires_grad=True)   b: tensor([[0.0942]], requires_grad=True)\n",
      "Epoch 18/100, Loss: 0.4464966058731079\n",
      "w: tensor([[ 0.9211],\n",
      "        [-2.9503]], requires_grad=True)   b: tensor([[0.0958]], requires_grad=True)\n",
      "Epoch 19/100, Loss: 0.4429909288883209\n",
      "w: tensor([[ 0.9474],\n",
      "        [-2.9964]], requires_grad=True)   b: tensor([[0.0973]], requires_grad=True)\n",
      "Epoch 20/100, Loss: 0.439619243144989\n",
      "w: tensor([[ 0.9723],\n",
      "        [-3.0416]], requires_grad=True)   b: tensor([[0.0987]], requires_grad=True)\n",
      "Epoch 21/100, Loss: 0.43637001514434814\n",
      "w: tensor([[ 0.9958],\n",
      "        [-3.0859]], requires_grad=True)   b: tensor([[0.1000]], requires_grad=True)\n",
      "Epoch 22/100, Loss: 0.4332335889339447\n",
      "w: tensor([[ 1.0180],\n",
      "        [-3.1294]], requires_grad=True)   b: tensor([[0.1012]], requires_grad=True)\n",
      "Epoch 23/100, Loss: 0.4302010238170624\n",
      "w: tensor([[ 1.0392],\n",
      "        [-3.1721]], requires_grad=True)   b: tensor([[0.1024]], requires_grad=True)\n",
      "Epoch 24/100, Loss: 0.4272646903991699\n",
      "w: tensor([[ 1.0594],\n",
      "        [-3.2140]], requires_grad=True)   b: tensor([[0.1036]], requires_grad=True)\n",
      "Epoch 25/100, Loss: 0.4244181215763092\n",
      "w: tensor([[ 1.0786],\n",
      "        [-3.2552]], requires_grad=True)   b: tensor([[0.1047]], requires_grad=True)\n",
      "Epoch 26/100, Loss: 0.42165514826774597\n",
      "w: tensor([[ 1.0971],\n",
      "        [-3.2957]], requires_grad=True)   b: tensor([[0.1057]], requires_grad=True)\n",
      "Epoch 27/100, Loss: 0.41897040605545044\n",
      "w: tensor([[ 1.1148],\n",
      "        [-3.3355]], requires_grad=True)   b: tensor([[0.1067]], requires_grad=True)\n",
      "Epoch 28/100, Loss: 0.4163590669631958\n",
      "w: tensor([[ 1.1318],\n",
      "        [-3.3747]], requires_grad=True)   b: tensor([[0.1077]], requires_grad=True)\n",
      "Epoch 29/100, Loss: 0.41381675004959106\n",
      "w: tensor([[ 1.1482],\n",
      "        [-3.4132]], requires_grad=True)   b: tensor([[0.1086]], requires_grad=True)\n",
      "Epoch 30/100, Loss: 0.4113398790359497\n",
      "w: tensor([[ 1.1640],\n",
      "        [-3.4511]], requires_grad=True)   b: tensor([[0.1095]], requires_grad=True)\n",
      "Epoch 31/100, Loss: 0.4089241325855255\n",
      "w: tensor([[ 1.1793],\n",
      "        [-3.4884]], requires_grad=True)   b: tensor([[0.1104]], requires_grad=True)\n",
      "Epoch 32/100, Loss: 0.4065665602684021\n",
      "w: tensor([[ 1.1942],\n",
      "        [-3.5251]], requires_grad=True)   b: tensor([[0.1112]], requires_grad=True)\n",
      "Epoch 33/100, Loss: 0.404264360666275\n",
      "w: tensor([[ 1.2085],\n",
      "        [-3.5612]], requires_grad=True)   b: tensor([[0.1121]], requires_grad=True)\n",
      "Epoch 34/100, Loss: 0.40201473236083984\n",
      "w: tensor([[ 1.2225],\n",
      "        [-3.5968]], requires_grad=True)   b: tensor([[0.1129]], requires_grad=True)\n",
      "Epoch 35/100, Loss: 0.39981481432914734\n",
      "w: tensor([[ 1.2360],\n",
      "        [-3.6319]], requires_grad=True)   b: tensor([[0.1137]], requires_grad=True)\n",
      "Epoch 36/100, Loss: 0.3976624608039856\n",
      "w: tensor([[ 1.2492],\n",
      "        [-3.6665]], requires_grad=True)   b: tensor([[0.1144]], requires_grad=True)\n",
      "Epoch 37/100, Loss: 0.39555537700653076\n",
      "w: tensor([[ 1.2621],\n",
      "        [-3.7006]], requires_grad=True)   b: tensor([[0.1152]], requires_grad=True)\n",
      "Epoch 38/100, Loss: 0.3934917747974396\n",
      "w: tensor([[ 1.2746],\n",
      "        [-3.7342]], requires_grad=True)   b: tensor([[0.1159]], requires_grad=True)\n",
      "Epoch 39/100, Loss: 0.3914695382118225\n",
      "w: tensor([[ 1.2869],\n",
      "        [-3.7674]], requires_grad=True)   b: tensor([[0.1166]], requires_grad=True)\n",
      "Epoch 40/100, Loss: 0.38948702812194824\n",
      "w: tensor([[ 1.2989],\n",
      "        [-3.8001]], requires_grad=True)   b: tensor([[0.1173]], requires_grad=True)\n",
      "Epoch 41/100, Loss: 0.3875424861907959\n",
      "w: tensor([[ 1.3106],\n",
      "        [-3.8323]], requires_grad=True)   b: tensor([[0.1180]], requires_grad=True)\n",
      "Epoch 42/100, Loss: 0.3856346905231476\n",
      "w: tensor([[ 1.3220],\n",
      "        [-3.8642]], requires_grad=True)   b: tensor([[0.1187]], requires_grad=True)\n",
      "Epoch 43/100, Loss: 0.38376176357269287\n",
      "w: tensor([[ 1.3333],\n",
      "        [-3.8956]], requires_grad=True)   b: tensor([[0.1193]], requires_grad=True)\n",
      "Epoch 44/100, Loss: 0.3819226920604706\n",
      "w: tensor([[ 1.3443],\n",
      "        [-3.9267]], requires_grad=True)   b: tensor([[0.1200]], requires_grad=True)\n",
      "Epoch 45/100, Loss: 0.3801162540912628\n",
      "w: tensor([[ 1.3551],\n",
      "        [-3.9573]], requires_grad=True)   b: tensor([[0.1206]], requires_grad=True)\n",
      "Epoch 46/100, Loss: 0.3783411383628845\n",
      "w: tensor([[ 1.3657],\n",
      "        [-3.9876]], requires_grad=True)   b: tensor([[0.1213]], requires_grad=True)\n",
      "Epoch 47/100, Loss: 0.3765963613986969\n",
      "w: tensor([[ 1.3761],\n",
      "        [-4.0175]], requires_grad=True)   b: tensor([[0.1219]], requires_grad=True)\n",
      "Epoch 48/100, Loss: 0.3748806416988373\n",
      "w: tensor([[ 1.3864],\n",
      "        [-4.0470]], requires_grad=True)   b: tensor([[0.1225]], requires_grad=True)\n",
      "Epoch 49/100, Loss: 0.3731931447982788\n",
      "w: tensor([[ 1.3965],\n",
      "        [-4.0762]], requires_grad=True)   b: tensor([[0.1231]], requires_grad=True)\n",
      "Epoch 50/100, Loss: 0.3715323507785797\n",
      "w: tensor([[ 1.4064],\n",
      "        [-4.1051]], requires_grad=True)   b: tensor([[0.1237]], requires_grad=True)\n",
      "Epoch 51/100, Loss: 0.3698982000350952\n",
      "w: tensor([[ 1.4161],\n",
      "        [-4.1337]], requires_grad=True)   b: tensor([[0.1242]], requires_grad=True)\n",
      "Epoch 52/100, Loss: 0.3682897984981537\n",
      "w: tensor([[ 1.4258],\n",
      "        [-4.1619]], requires_grad=True)   b: tensor([[0.1248]], requires_grad=True)\n",
      "Epoch 53/100, Loss: 0.36670589447021484\n",
      "w: tensor([[ 1.4352],\n",
      "        [-4.1898]], requires_grad=True)   b: tensor([[0.1254]], requires_grad=True)\n",
      "Epoch 54/100, Loss: 0.3651459813117981\n",
      "w: tensor([[ 1.4446],\n",
      "        [-4.2174]], requires_grad=True)   b: tensor([[0.1259]], requires_grad=True)\n",
      "Epoch 55/100, Loss: 0.36360907554626465\n",
      "w: tensor([[ 1.4538],\n",
      "        [-4.2447]], requires_grad=True)   b: tensor([[0.1265]], requires_grad=True)\n",
      "Epoch 56/100, Loss: 0.3620946407318115\n",
      "w: tensor([[ 1.4629],\n",
      "        [-4.2717]], requires_grad=True)   b: tensor([[0.1270]], requires_grad=True)\n",
      "Epoch 57/100, Loss: 0.3606022596359253\n",
      "w: tensor([[ 1.4718],\n",
      "        [-4.2985]], requires_grad=True)   b: tensor([[0.1276]], requires_grad=True)\n",
      "Epoch 58/100, Loss: 0.35913121700286865\n",
      "w: tensor([[ 1.4807],\n",
      "        [-4.3249]], requires_grad=True)   b: tensor([[0.1281]], requires_grad=True)\n",
      "Epoch 59/100, Loss: 0.357681006193161\n",
      "w: tensor([[ 1.4894],\n",
      "        [-4.3511]], requires_grad=True)   b: tensor([[0.1286]], requires_grad=True)\n",
      "Epoch 60/100, Loss: 0.35625067353248596\n",
      "w: tensor([[ 1.4981],\n",
      "        [-4.3770]], requires_grad=True)   b: tensor([[0.1291]], requires_grad=True)\n",
      "Epoch 61/100, Loss: 0.35483989119529724\n",
      "w: tensor([[ 1.5066],\n",
      "        [-4.4027]], requires_grad=True)   b: tensor([[0.1296]], requires_grad=True)\n",
      "Epoch 62/100, Loss: 0.35344788432121277\n",
      "w: tensor([[ 1.5150],\n",
      "        [-4.4281]], requires_grad=True)   b: tensor([[0.1301]], requires_grad=True)\n",
      "Epoch 63/100, Loss: 0.3520742952823639\n",
      "w: tensor([[ 1.5234],\n",
      "        [-4.4533]], requires_grad=True)   b: tensor([[0.1306]], requires_grad=True)\n",
      "Epoch 64/100, Loss: 0.3507183790206909\n",
      "w: tensor([[ 1.5316],\n",
      "        [-4.4782]], requires_grad=True)   b: tensor([[0.1311]], requires_grad=True)\n",
      "Epoch 65/100, Loss: 0.34938040375709534\n",
      "w: tensor([[ 1.5397],\n",
      "        [-4.5029]], requires_grad=True)   b: tensor([[0.1316]], requires_grad=True)\n",
      "Epoch 66/100, Loss: 0.34805920720100403\n",
      "w: tensor([[ 1.5478],\n",
      "        [-4.5274]], requires_grad=True)   b: tensor([[0.1321]], requires_grad=True)\n",
      "Epoch 67/100, Loss: 0.3467545211315155\n",
      "w: tensor([[ 1.5558],\n",
      "        [-4.5517]], requires_grad=True)   b: tensor([[0.1326]], requires_grad=True)\n",
      "Epoch 68/100, Loss: 0.34546583890914917\n",
      "w: tensor([[ 1.5637],\n",
      "        [-4.5757]], requires_grad=True)   b: tensor([[0.1330]], requires_grad=True)\n",
      "Epoch 69/100, Loss: 0.3441930413246155\n",
      "w: tensor([[ 1.5715],\n",
      "        [-4.5995]], requires_grad=True)   b: tensor([[0.1335]], requires_grad=True)\n",
      "Epoch 70/100, Loss: 0.34293603897094727\n",
      "w: tensor([[ 1.5792],\n",
      "        [-4.6232]], requires_grad=True)   b: tensor([[0.1340]], requires_grad=True)\n",
      "Epoch 71/100, Loss: 0.3416937291622162\n",
      "w: tensor([[ 1.5869],\n",
      "        [-4.6466]], requires_grad=True)   b: tensor([[0.1344]], requires_grad=True)\n",
      "Epoch 72/100, Loss: 0.34046608209609985\n",
      "w: tensor([[ 1.5945],\n",
      "        [-4.6698]], requires_grad=True)   b: tensor([[0.1349]], requires_grad=True)\n",
      "Epoch 73/100, Loss: 0.3392528295516968\n",
      "w: tensor([[ 1.6020],\n",
      "        [-4.6928]], requires_grad=True)   b: tensor([[0.1353]], requires_grad=True)\n",
      "Epoch 74/100, Loss: 0.3380536139011383\n",
      "w: tensor([[ 1.6094],\n",
      "        [-4.7156]], requires_grad=True)   b: tensor([[0.1358]], requires_grad=True)\n",
      "Epoch 75/100, Loss: 0.33686840534210205\n",
      "w: tensor([[ 1.6168],\n",
      "        [-4.7383]], requires_grad=True)   b: tensor([[0.1362]], requires_grad=True)\n",
      "Epoch 76/100, Loss: 0.33569636940956116\n",
      "w: tensor([[ 1.6241],\n",
      "        [-4.7607]], requires_grad=True)   b: tensor([[0.1367]], requires_grad=True)\n",
      "Epoch 77/100, Loss: 0.33453771471977234\n",
      "w: tensor([[ 1.6314],\n",
      "        [-4.7830]], requires_grad=True)   b: tensor([[0.1371]], requires_grad=True)\n",
      "Epoch 78/100, Loss: 0.33339202404022217\n",
      "w: tensor([[ 1.6385],\n",
      "        [-4.8050]], requires_grad=True)   b: tensor([[0.1375]], requires_grad=True)\n",
      "Epoch 79/100, Loss: 0.33225879073143005\n",
      "w: tensor([[ 1.6457],\n",
      "        [-4.8269]], requires_grad=True)   b: tensor([[0.1379]], requires_grad=True)\n",
      "Epoch 80/100, Loss: 0.33113762736320496\n",
      "w: tensor([[ 1.6527],\n",
      "        [-4.8487]], requires_grad=True)   b: tensor([[0.1384]], requires_grad=True)\n",
      "Epoch 81/100, Loss: 0.33002859354019165\n",
      "w: tensor([[ 1.6597],\n",
      "        [-4.8703]], requires_grad=True)   b: tensor([[0.1388]], requires_grad=True)\n",
      "Epoch 82/100, Loss: 0.32893088459968567\n",
      "w: tensor([[ 1.6667],\n",
      "        [-4.8917]], requires_grad=True)   b: tensor([[0.1392]], requires_grad=True)\n",
      "Epoch 83/100, Loss: 0.32784485816955566\n",
      "w: tensor([[ 1.6736],\n",
      "        [-4.9129]], requires_grad=True)   b: tensor([[0.1396]], requires_grad=True)\n",
      "Epoch 84/100, Loss: 0.326770544052124\n",
      "w: tensor([[ 1.6804],\n",
      "        [-4.9340]], requires_grad=True)   b: tensor([[0.1400]], requires_grad=True)\n",
      "Epoch 85/100, Loss: 0.32570719718933105\n",
      "w: tensor([[ 1.6872],\n",
      "        [-4.9549]], requires_grad=True)   b: tensor([[0.1404]], requires_grad=True)\n",
      "Epoch 86/100, Loss: 0.32465478777885437\n",
      "w: tensor([[ 1.6939],\n",
      "        [-4.9757]], requires_grad=True)   b: tensor([[0.1408]], requires_grad=True)\n",
      "Epoch 87/100, Loss: 0.323612779378891\n",
      "w: tensor([[ 1.7006],\n",
      "        [-4.9963]], requires_grad=True)   b: tensor([[0.1412]], requires_grad=True)\n",
      "Epoch 88/100, Loss: 0.3225809931755066\n",
      "w: tensor([[ 1.7072],\n",
      "        [-5.0168]], requires_grad=True)   b: tensor([[0.1416]], requires_grad=True)\n",
      "Epoch 89/100, Loss: 0.3215596675872803\n",
      "w: tensor([[ 1.7138],\n",
      "        [-5.0371]], requires_grad=True)   b: tensor([[0.1420]], requires_grad=True)\n",
      "Epoch 90/100, Loss: 0.320548415184021\n",
      "w: tensor([[ 1.7203],\n",
      "        [-5.0573]], requires_grad=True)   b: tensor([[0.1424]], requires_grad=True)\n",
      "Epoch 91/100, Loss: 0.3195469379425049\n",
      "w: tensor([[ 1.7268],\n",
      "        [-5.0774]], requires_grad=True)   b: tensor([[0.1428]], requires_grad=True)\n",
      "Epoch 92/100, Loss: 0.3185553252696991\n",
      "w: tensor([[ 1.7332],\n",
      "        [-5.0973]], requires_grad=True)   b: tensor([[0.1431]], requires_grad=True)\n",
      "Epoch 93/100, Loss: 0.3175733983516693\n",
      "w: tensor([[ 1.7396],\n",
      "        [-5.1170]], requires_grad=True)   b: tensor([[0.1435]], requires_grad=True)\n",
      "Epoch 94/100, Loss: 0.3166009187698364\n",
      "w: tensor([[ 1.7459],\n",
      "        [-5.1367]], requires_grad=True)   b: tensor([[0.1439]], requires_grad=True)\n",
      "Epoch 95/100, Loss: 0.3156373202800751\n",
      "w: tensor([[ 1.7522],\n",
      "        [-5.1562]], requires_grad=True)   b: tensor([[0.1443]], requires_grad=True)\n",
      "Epoch 96/100, Loss: 0.31468263268470764\n",
      "w: tensor([[ 1.7585],\n",
      "        [-5.1756]], requires_grad=True)   b: tensor([[0.1446]], requires_grad=True)\n",
      "Epoch 97/100, Loss: 0.3137367069721222\n",
      "w: tensor([[ 1.7647],\n",
      "        [-5.1948]], requires_grad=True)   b: tensor([[0.1450]], requires_grad=True)\n",
      "Epoch 98/100, Loss: 0.3127998113632202\n",
      "w: tensor([[ 1.7708],\n",
      "        [-5.2139]], requires_grad=True)   b: tensor([[0.1454]], requires_grad=True)\n",
      "Epoch 99/100, Loss: 0.311871200799942\n",
      "w: tensor([[ 1.7770],\n",
      "        [-5.2329]], requires_grad=True)   b: tensor([[0.1457]], requires_grad=True)\n",
      "Epoch 100/100, Loss: 0.3109511137008667\n",
      "w: tensor([[ 1.7831],\n",
      "        [-5.2518]], requires_grad=True)   b: tensor([[0.1461]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "n_item  = 1000 # 数据条目M\n",
    "n_feature = 2 # 特征维度\n",
    "learning_rate = 0.001 # 学习率\n",
    "epochs = 100 # 训练轮数\n",
    "\n",
    "torch.manual_seed(123)\n",
    "data_x = torch.randn(size = (n_item, n_feature)).float()\n",
    "data_y = torch.where(torch.subtract(data_x[:,0]*0.5,data_x[:,1]*1.5)>0,1.,0.).float()\n",
    "\n",
    "class LogisticRegressionManually(object):\n",
    "    def __init__(self):\n",
    "        self.w = torch.randn(size = (n_feature, 1), requires_grad=True)\n",
    "        self.b = torch.zeros(size=(1,1), requires_grad=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(f'w: {self.w}   x: {x}   b: {self.b}')\n",
    "        print(f'w*x: {torch.matmul(self.w.transpose(0,1),x)}')\n",
    "        return F.sigmoid(torch.matmul(self.w.transpose(0,1),x)+self.b)\n",
    "    @staticmethod\n",
    "    def loss_func(y_hat,y):\n",
    "        return -(torch.log(y_hat)*y+(1-y)*torch.log(1-y_hat))\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(epochs):\n",
    "        #    1. load data\n",
    "            for step in range(n_item):\n",
    "                y_hat = self.forward(data_x[step])\n",
    "                y = data_y[step]\n",
    "                loss = self.loss_func(y_hat,y)\n",
    "                loss.backward()\n",
    "                with torch.no_grad():\n",
    "                    self.w.data -= learning_rate * self.w.grad.data\n",
    "                    self.b.data -= learning_rate * self.b.grad.data\n",
    "                self.w.grad.data.zero_()\n",
    "                self.b.grad.data.zero_()\n",
    "                \n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "            print(f'''w: {self.w}   b: {self.b}''')\n",
    "        \n",
    "\n",
    "lrm = LogisticRegressionManually()\n",
    "lrm.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

1
00:00:01,460 --> 00:00:06,735
In this video, you see a very useful idea called vectorization.

2
00:00:06,735 --> 00:00:15,870
When you're implementing a learning algorithm, using vectorization will both make your code shorter and also make it run much more efficiently.

3
00:00:15,870 --> 00:00:28,305
Learning how to write vectorized code will allow you to also take advantage of modern numerical linear algebra libraries, as well as maybe even GPU hardware that stands for graphics processing unit.

4
00:00:28,305 --> 00:00:38,835
This is hardware objectively designed to speed up computer graphics in your computer, but turns out can be used when you write vectorized code to also help you execute your code much more quickly.

5
00:00:38,835 --> 00:00:42,750
Let's look at a concrete example of what vectorization means.

6
00:00:42,750 --> 00:00:56,075
Here's an example with parameters w and b, where w is a vector with three numbers, and you also have a vector of features x with also three numbers.

7
00:00:56,075 --> 00:00:59,575
Here n is equal to 3.

8
00:00:59,575 --> 00:01:10,420
Notice that in linear algebra, the index or the counting starts from 1 and so the first value is subscripted w1 and x1.

9
00:01:10,420 --> 00:01:18,485
In Python code, you can define these variables w, b, and x using arrays like this.

10
00:01:18,485 --> 00:01:30,980
Here, I'm actually using a numerical linear algebra library in Python called NumPy, which is by far the most widely used numerical linear algebra library in Python and in machine learning.

11
00:01:30,980 --> 00:01:44,630
Because in Python, the indexing of arrays while counting in arrays starts from 0, you would access the first value of w using w square brackets 0.

12
00:01:44,630 --> 00:01:52,390
The second value using w square bracket 1, and the third and using w square bracket 2.

13
00:01:52,390 --> 00:02:00,105
The indexing here, it goes from 0,1 to 2 rather than 1, 2 to 3.

14
00:02:00,105 --> 00:02:08,570
Similarly, to access individual features of x, you will use x0, x1, and x2.

15
00:02:08,570 --> 00:02:14,705
Many programming languages including Python start counting from 0 rather than 1.

16
00:02:14,705 --> 00:02:21,415
Now, let's look at an implementation without vectorization for computing the model's prediction.

17
00:02:21,415 --> 00:02:23,880
In codes, it will look like this.

18
00:02:23,880 --> 00:02:30,345
You take each parameter w and multiply it by his associated feature.

19
00:02:30,345 --> 00:02:43,710
Now, you could write your code like this, but what if n isn't three but instead n is a 100 or a 100,000 is both inefficient for you the code and inefficient for your computer to compute.

20
00:02:43,710 --> 00:02:49,400
Here's another way. Without using vectorization but using a for loop.

21
00:02:49,400 --> 00:03:04,740
In math, you can use a summation operator to add all the products of w_j and x_j for j equals 1 through n. Then I'll cite the summation you add b at the end.

22
00:03:04,740 --> 00:03:15,900
To summation goes from j equals 1 up to and including n. For n equals 3, j therefore goes from 1, 2 to 3.

23
00:03:15,900 --> 00:03:19,450
In code, you can initialize after 0.

24
00:03:19,450 --> 00:03:28,075
Then for j in range from 0 to n, this actually makes j go from 0 to n minus 1.

25
00:03:28,075 --> 00:03:36,065
From 0, 1 to 2, you can then add to f the product of w_j times x_j.

26
00:03:36,065 --> 00:03:39,880
Finally, outside the for loop, you add b.

27
00:03:39,880 --> 00:03:49,775
Notice that in Python, the range 0 to n means that j goes from 0 all the way to n minus 1 and does not include n itself.

28
00:03:49,775 --> 00:03:54,320
This is written range n in Python.

29
00:03:54,320 --> 00:03:59,765
But in this video, I added a 0 here just to emphasize that it starts from 0.

30
00:03:59,765 --> 00:04:14,180
While this implementation is a bit better than the first one, this still doesn't use factorization, and isn't that efficient? Now, let's look at how you can do this using vectorization.

31
00:04:14,180 --> 00:04:38,050
This is the math expression of the function f, which is the dot product of w and x plus b, and now you can implement this with a single line of code by computing fp equals np dot dot, I said dot dot because the first dot is the period and the second dot is the function or the method called DOT.

32
00:04:38,050 --> 00:04:51,320
But is fp equals np dot dot w comma x and this implements the mathematical dot products between the vectors w and x.

33
00:04:51,320 --> 00:04:55,015
Then finally, you can add b to it at the end.

34
00:04:55,015 --> 00:05:08,875
This NumPy dot function is a vectorized implementation of the dot product operation between two vectors and especially when n is large, this will run much faster than the two previous code examples.

35
00:05:08,875 --> 00:05:13,725
I want to emphasize that vectorization actually has two distinct benefits.

36
00:05:13,725 --> 00:05:28,360
First, it makes code shorter, is now just one line of code. Isn't that cool? Second, it also results in your code running much faster than either of the two previous implementations that did not use vectorization.

37
00:05:28,360 --> 00:05:35,425
The reason that the vectorized implementation is much faster is behind the scenes.

38
00:05:35,425 --> 00:05:54,045
The NumPy dot function is able to use parallel hardware in your computer and this is true whether you're running this on a normal computer, that is on a normal computer CPU or if you are using a GPU, a graphics processor unit, that's often used to accelerate machine learning jobs.

39
00:05:54,045 --> 00:06:06,469
The ability of the NumPy dot function to use parallel hardware makes it much more efficient than the for loop or the sequential calculation that we saw previously.

40
00:06:06,469 --> 00:06:21,800
Now, this version is much more practical when n is large because you are not typing w0 times x0 plus w1 times x1 plus lots of additional terms like you would have had for the previous version.

41
00:06:21,800 --> 00:06:31,210
But while this saves a lot on the typing, is still not that computationally efficient because it still doesn't use vectorization.

42
00:06:31,210 --> 00:06:42,500
To recap, vectorization makes your code shorter, so hopefully easier to write and easier for you or others to read, and it also makes it run much faster.

43
00:06:42,500 --> 00:06:47,795
But honest, this magic behind vectorization that makes this run so much faster.

44
00:06:47,795 --> 00:06:54,540
Let's take a look at what your computer is actually doing behind the scenes to make vectorized code run so much faster.


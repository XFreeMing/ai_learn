### 视频作者观点总结

#### 1. 成本函数的作用

- 成本函数用于衡量特定参数集对训练数据的拟合程度，并帮助选择更好的参数（视频字幕 1：00:00:00,800 - 00:00:09,705）。

#### 2. 逻辑回归的成本函数

- 视频指出，平方误差成本函数不是逻辑回归的理想成本函数（视频字幕 3：00:00:13,980 - 00:00:21,810）。
- 视频介绍了一个不同的成本函数，可以帮助选择更好的逻辑回归参数（视频字幕 4：00:00:21,810 - 00:00:28,485）。

#### 3. 逻辑回归模型的训练集

- 训练集的每一行可能对应一个病人的诊断信息（视频字幕 6：00:00:33,370 - 00:00:44,035）。
- 每个训练样本有多个特征，如肿瘤大小、病人年龄等，总共有 n 个特征（视频字幕 8：00:01:01,745 - 00:01:06,085）。
- 目标标签 y 只有两个值，0 或 1（视频字幕 10：00:01:06,085 - 00:01:15,505）。

#### 4. 逻辑回归模型的定义

- 对数回归模型由方程 f(x) = 1 / (1 + e^(-wx + b))定义（视频字幕 11：00:01:15,505 - 00:01:21,540）。

#### 5. 平方误差成本函数的问题

- 尝试将平方误差成本函数应用于对数回归会导致非凸成本函数，存在许多局部最小值（视频字幕 18：00:02:10,575 - 00:02:25,585）。
- 这意味着使用梯度下降时可能会陷入局部最小值（视频字幕 20：00:02:32,100 - 00:02:37,095）。

#### 6. 逻辑回归的新成本函数

- 视频提出了一个新的成本函数，使成本函数再次成为凸函数，梯度下降可以保证收敛到全局最小值（视频字幕 23：00:02:48,740 - 00:02:55,300）。
- 新的成本函数定义为 J(w, b) = 1/2 _ Σ(y _ log(f(x)) + (1-y) \* log(1-f(x)))（视频字幕 28：00:03:16,040 - 00:03:22,415）。

#### 7. 新成本函数的损失函数

- 损失函数 L 定义为：如果 y=1，损失为-log(f(x))；如果 y=0，损失为-log(1-f(x))（视频字幕 35：00:04:30,620 - 00:04:48,320）。
- 这种损失函数鼓励算法更准确地预测，因为当预测值接近真实值时，损失最小（视频字幕 52：00:07:10,380 - 00:07:24,580）。

#### 8. 成本函数的凸性

- 通过选择这种损失函数，整体成本函数将是凸函数，因此可以可靠地使用梯度下降找到全局最小值（视频字幕 69：00:09:44,500 - 00:09:57,055）。

#### 9. 成本函数的计算

- 成本函数是整个训练集的函数，是损失函数在各个训练样本上的平均值（视频字幕 71：00:10:14,425 - 00:10:29,845）。
- 通过找到最小化成本函数的参数 w 和 b，可以得到对数回归的一组很好的参数（视频字幕 73：00:10:43,675 - 00:10:56,375）。

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本段结论\n",
    "本文提出了一个新的框架（TRAD）来解决这些问题。TRAD首先进行思想检索，通过思想匹配实现步骤级演示选择，从而产生更有帮助的演示和更少的无关输入噪声。然后，TRAD引入了对齐决策，通过将检索到的演示步骤与其前后步骤相结合，从而实现对不完美思想的容忍，并提供了在更多上下文和更少噪声之间的平衡选择。在ALFWorld和Mind2Web基准测试中的大量实验表明，TRAD不仅优于最先进的模型，而且有效地帮助减少噪声并促进泛化。此外，TRAD已经在全球商业保险公司的实际场景中部署，并提高了机器人流程自动化的成功率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM’s wide knowledge and text-understanding ability. \n",
    "> 由于LLM的广泛知识和文本理解能力，已经为不同任务构建了大量的大型语言模型（LLM）代理。\n",
    "- Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. \n",
    "> 在这些工作中，许多利用上下文示例实现泛化而无需微调，而很少有人考虑如何选择和有效利用这些示例的问题。\n",
    "- Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent’s overall performance in some sequential decision making tasks. \n",
    "> 最近，基于轨迹级检索的方法，使用任务元数据并使用轨迹作为上下文示例，已被提出来提高代理在某些顺序决策任务中的整体性能。\n",
    "- However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. \n",
    "> 然而，由于检索到的示例缺乏特定于任务的状态转移动态和包含大量无关上下文的长输入，这些方法可能存在问题。\n",
    "- In this paper, we propose a novel framework (TRAD) to address these issues. \n",
    "> 在本文中，我们提出了一个新的框架（TRAD）来解决这些问题。\n",
    "- TRAD first conducts Thought Retrieval, achieving step-level demonstration selection via thought matching, leading to more helpful demonstrations and less irrelevant input noise. \n",
    "> TRAD首先进行思想检索，通过思想匹配实现步骤级演示选择，从而产生更有帮助的演示和更少的无关输入噪声。\n",
    "- Then, TRAD introduces Aligned Decision, complementing retrieved demonstration steps with their previous or subsequent steps, which enables tolerance for imperfect thought and provides a choice for balance between more context and less noise. \n",
    "> 然后，TRAD引入了对齐决策，通过将检索到的演示步骤与其前后步骤相结合，从而实现对不完美思想的容忍，并提供了在更多上下文和更少噪声之间的平衡选择。\n",
    "- Extensive experiments on ALFWorld and Mind2Web benchmarks show that TRAD not only outperforms state-of-the-art models but also effectively helps in reducing noise and promoting generalization. \n",
    "> 在ALFWorld和Mind2Web基准测试中的大量实验表明，TRAD不仅优于最先进的模型，而且有效地帮助减少噪声并促进泛化。\n",
    "- Furthermore, TRAD has been deployed in real-world scenarios of a global business insurance company and improves the success rate of robotic process automation. \n",
    "> 此外，TRAD已经在全球商业保险公司的实际场景中部署，并提高了机器人流程自动化的成功率。\n",
    "\n",
    "## 总结\n",
    "本文提出了一个新的框架（TRAD）来解决这些问题。TRAD首先进行思想检索，通过思想匹配实现步骤级演示选择，从而产生更有帮助的演示和更少的无关输入噪声。然后，TRAD引入了对齐决策，通过将检索到的演示步骤与其前后步骤相结合，从而实现对不完美思想的容忍，并提供了在更多上下文和更少噪声之间的平衡选择。在ALFWorld和Mind2Web基准测试中的大量实验表明，TRAD不仅优于最先进的模型，而且有效地帮助减少噪声并促进泛化。此外，TRAD已经在全球商业保险公司的实际场景中部署，并提高了机器人流程自动化的成功率。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

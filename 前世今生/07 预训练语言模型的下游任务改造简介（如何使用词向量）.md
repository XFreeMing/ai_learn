<div><a href="https://space.bilibili.com/383551518?spm_id_from=333.1007.0.0" style="text-decoration: none; color: rgba(7, 137, 224, 1)" target="_blank">博客配套视频链接: https://space.bilibili.com/383551518?spm_id_from=333.1007.0.0  b 站直接看</a></div>

<div><a href="https://github.com/nickchen121/Pre-training-language-model" style="text-decoration: none; color: rgba(7, 137, 224, 1)" target="_blank">配套 github 链接：https://github.com/nickchen121/Pre-training-language-model</a></div>

<div><a href="https://www.cnblogs.com/nickchen121/p/16470443.html" style="text-decoration: none; color: rgba(7, 137, 224, 1)" target="_blank">配套博客链接：https://www.cnblogs.com/nickchen121/p/15105048.html</a></div><br>

# Word2Vec --》 是一个神经网络语言模型，其次他的主要任务是做（生成词向量，Q）

![image-20220614194418918](../../Library/Application Support/typora-user-images/image-20220614194418918.png)

Word2Vec 模型是不是预训练模型？（是）

一定是

什么是预训练？

给出两个任务 A 和 B，任务 A 已经做出了模型 A，任务 B 无法解决（通过使用模型 A，加快任务的解决）



给你一个 NLP 里面的任务，给一个问题 X（Ni+ck），给出一个回答 Y（handsome）

![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/we%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83.jpg)

预训练语言模型终于出来（给出一句话，我们先使用独热编码（一一对应的一种表查询），再使用Word2Vec 预训练好的 Q 矩阵直接得到词向量，然后进行接下来的任务）

1. 冻结：可以不改变 Q 矩阵
2. 微调：随着任务的改变，改变 Q 矩阵